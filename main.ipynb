{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731d5e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91a6d9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.53.0)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers peft accelerate datasets bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c11878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88afa192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from datasets import load_dataset\n",
    "from itertools import islice\n",
    "from datasets import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d583ba45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0225df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1. Î™®Îç∏ Î∞è ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î°úÎî©\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b67b282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5642bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. QLoRA ÏÑ§Ï†ï\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]  # üî• ÌïµÏã¨\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b577da88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "224303dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd78cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e01e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎî© Î∞è Ï†ÑÏ≤òÎ¶¨\n",
    "# dataset = load_dataset(\"codeparrot/github-code-clean\", split=\"train[:5000]\")  # ÏùºÎ∂ÄÎßå ÏÇ¨Ïö© (ÏòàÏ†ú Î™©Ï†Å)\n",
    "!export HF_DATASETS_VERBOSE=1\n",
    "dataset = load_dataset(\n",
    "    path=\"/datasets/github-code/github-code-clean\",\n",
    "    data_dir=\"/datasets/github-code/hf_data\",\n",
    "    cache_dir=\"/datasets/github-code/hf_cache\",\n",
    "    trust_remote_code=True,\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "# ÏïûÏóêÏÑú 10000Í∞úÎßå Ï∂îÏ∂ú\n",
    "subset = list(islice(dataset[\"train\"], 10000))\n",
    "\n",
    "# Hugging Face DatasetÏúºÎ°ú Î≥ÄÌôò\n",
    "dataset = Dataset.from_list(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ac3501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['code', 'repo_name', 'path', 'language', 'license', 'size'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7561336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57684df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:02<00:00, 4544.65 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 4. ÏΩîÎìú Ï†ÑÏö© ÌîÑÎ°¨ÌîÑÌä∏ Ìè¨Îß∑\n",
    "def format_example(example):\n",
    "    code = example[\"code\"]\n",
    "    return {\"text\": f\"# Python code snippet:\\n{code.strip()}\"}\n",
    "\n",
    "dataset = dataset.map(format_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f99cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ae97618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:18<00:00, 526.67 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 5. ÌÜ†ÌÅ¨ÎÇòÏù¥Ïßï + ÎùºÎ≤® Ï∂îÍ∞Ä (language modeling Ïö©)\n",
    "def tokenize_and_add_labels(example):\n",
    "    text = example.get(\"code\") or example.get(\"text\") or example.get(\"content\")\n",
    "    result = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()  # causal LMÏö© ÎùºÎ≤® ÏÑ§Ï†ï\n",
    "    return result\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_and_add_labels,\n",
    "    batched=True,\n",
    "    remove_columns=dataset.column_names  # Î™®Îç∏Ïóê ÌïÑÏöîÌïú input_ids, attention_mask, labelsÎßå ÎÇ®ÍπÄ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13408bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d802c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ebc44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "# ÌïôÏäµ Í∞ÄÎä•Ìïú ÌååÎùºÎØ∏ÌÑ∞Îßå Ï∂îÏ∂ú (LoRA ÌååÎùºÎØ∏ÌÑ∞Îßå ÌïôÏäµ ÎåÄÏÉÅÏù∏ Í≤ΩÏö∞)\n",
    "optimizer = AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=2e-4,  # ÏùºÎ∞òÏ†ÅÏúºÎ°ú 2e-4 ~ 1e-4 ÏÇ¨Ïù¥ÏóêÏÑú ÏãúÏûë\n",
    "    weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e8b392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32842f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "# DataLoader ÏÑ§Ï†ï\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset,\n",
    "    batch_size=1,  # Ï£ºÏù∏ÎãòÏùò GPU Î©îÎ™®Î¶¨Ïóê Îî∞Îùº Ï°∞Ï†àÌïòÏÑ∏Ïöî (Ïòà: 2 ~ 8)\n",
    "    shuffle=True,\n",
    "    collate_fn=default_data_collator  # input_ids, attention_mask, labels ÏûêÎèô Ï†ïÎ†¨\n",
    ")\n",
    "\n",
    "model, train_dataloader, optimizer = accelerator.prepare(\n",
    "    model, train_dataloader, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8187df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f5c824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad7b5c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. ÌïôÏäµ ÏÑ§Ï†ï\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gemma-2b-code-finetuned\",\n",
    "    remove_unused_columns=False,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a512f701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff07a146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# 7. Trainer Íµ¨ÏÑ±\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d3e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0411212e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/10000 [00:01<5:10:53,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Step 0 - Loss: 0.7004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 101/10000 [00:53<1:24:25,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Step 100 - Loss: 4.8160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 114/10000 [00:59<1:24:40,  1.95it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "num_epochs=3\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Î°úÍ∑∏ Ï∂úÎ†•\n",
    "        if step % 100 == 0:\n",
    "            accelerator.print(f\"[Epoch {epoch}] Step {step} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    accelerator.print(f\"===> Epoch {epoch} ÏôÑÎ£å. ÌèâÍ∑† Loss: {total_loss / len(train_dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8beac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tokenized_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8dbd07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c89793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54975798",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9. Î™®Îç∏ Ï†ÄÏû•\n",
    "model.save_pretrained(\"./gemma-2b-code-finetuned\")\n",
    "tokenizer.save_pretrained(\"./gemma-2b-code-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b225494e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae93c354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a57e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6779bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
