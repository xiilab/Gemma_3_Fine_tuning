#!/usr/bin/env python3
"""
MLflow ì—…ë¡œë“œ ì¬ì‹œë„ ìŠ¤í¬ë¦½íŠ¸
í° íŒŒì¼ ì—…ë¡œë“œ ì‹œ ë°œìƒí•˜ëŠ” timeout ì˜¤ë¥˜ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import time
import requests
import mlflow
import mlflow.pytorch
from mlflow import MlflowClient
from datetime import datetime
import shutil
import tempfile
from pathlib import Path
import json
import threading
from tqdm import tqdm
import sys

# MLflow ì„¤ì •
MLFLOW_URI = "http://10.61.3.161:30366/"
mlflow.set_tracking_uri(MLFLOW_URI)
experiment_name = "Gemma-2b-Code-Finetuning"
mlflow.set_experiment(experiment_name)

def check_mlflow_server():
    """MLflow ì„œë²„ ìƒíƒœ í™•ì¸"""
    try:
        health_url = f"{MLFLOW_URI.rstrip('/')}/health"
        response = requests.get(health_url, timeout=10)
        if response.status_code == 200:
            print("âœ… MLflow ì„œë²„ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.")
            return True
        else:
            print(f"âŒ MLflow ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ MLflow ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
        return False

class UploadProgressTracker:
    """ì—…ë¡œë“œ ì§„í–‰ìƒí™© ì¶”ì  í´ë˜ìŠ¤"""
    def __init__(self, total_files, total_size_mb):
        self.total_files = total_files
        self.total_size_mb = total_size_mb
        self.completed_files = 0
        self.completed_size_mb = 0.0
        self.current_file = ""
        self.current_file_size_mb = 0.0
        self.start_time = time.time()
        self.lock = threading.Lock()
        
        # ì§„í–‰ë¥  í‘œì‹œ ë°”
        self.pbar = tqdm(
            total=total_files,
            desc="ğŸ“¤ ì—…ë¡œë“œ ì§„í–‰",
            unit="íŒŒì¼",
            ncols=100,
            bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}] {rate_fmt}"
        )
        
        # ìƒì„¸ ì •ë³´ í‘œì‹œìš© ë‘ ë²ˆì§¸ ë°”
        self.size_pbar = tqdm(
            total=total_size_mb,
            desc="ğŸ“Š ë°ì´í„° í¬ê¸°",
            unit="MB",
            ncols=100,
            position=1,
            bar_format="{l_bar}{bar}| {n:.1f}/{total:.1f}MB [{elapsed}<{remaining}] {rate_fmt}"
        )
    
    def update_current_file(self, filename, size_mb):
        """í˜„ì¬ ì—…ë¡œë“œ ì¤‘ì¸ íŒŒì¼ ì •ë³´ ì—…ë°ì´íŠ¸"""
        with self.lock:
            self.current_file = filename
            self.current_file_size_mb = size_mb
            self.pbar.set_postfix_str(f"í˜„ì¬: {filename} ({size_mb:.1f}MB)")
    
    def complete_file(self, size_mb):
        """íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ"""
        with self.lock:
            self.completed_files += 1
            self.completed_size_mb += size_mb
            self.pbar.update(1)
            self.size_pbar.update(size_mb)
            
            # ì†ë„ ê³„ì‚°
            elapsed = time.time() - self.start_time
            if elapsed > 0:
                speed_mb_s = self.completed_size_mb / elapsed
                self.size_pbar.set_postfix_str(f"ì†ë„: {speed_mb_s:.1f}MB/s")
    
    def close(self):
        """ì§„í–‰ë¥  í‘œì‹œ ì¢…ë£Œ"""
        self.pbar.close()
        self.size_pbar.close()
        
        # ìµœì¢… í†µê³„ ì¶œë ¥
        elapsed = time.time() - self.start_time
        avg_speed = self.completed_size_mb / elapsed if elapsed > 0 else 0
        
        print(f"\nğŸ“Š ì—…ë¡œë“œ ì™„ë£Œ í†µê³„:")
        print(f"   - ì´ íŒŒì¼: {self.completed_files}/{self.total_files}")
        print(f"   - ì´ í¬ê¸°: {self.completed_size_mb:.1f}/{self.total_size_mb:.1f}MB")
        print(f"   - ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ")
        print(f"   - í‰ê·  ì†ë„: {avg_speed:.1f}MB/s")

def upload_large_files_chunked(model_path, run_id, max_file_size_mb=100):
    """
    í° íŒŒì¼ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì—…ë¡œë“œí•˜ëŠ” í•¨ìˆ˜ (ì§„í–‰ìƒí™© í‘œì‹œ í¬í•¨)
    """
    client = MlflowClient()
    model_path = Path(model_path)
    
    print(f"ğŸ“¤ ëª¨ë¸ íŒŒì¼ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì—…ë¡œë“œ ì¤‘: {model_path}")
    
    # íŒŒì¼ í¬ê¸°ë³„ë¡œ ë¶„ë¥˜
    small_files = []
    large_files = []
    total_size_mb = 0
    
    print("ğŸ” íŒŒì¼ ë¶„ì„ ì¤‘...")
    file_scan_pbar = tqdm(desc="íŒŒì¼ ìŠ¤ìº”", unit="íŒŒì¼")
    
    for file_path in model_path.rglob("*"):
        if file_path.is_file():
            size_mb = file_path.stat().st_size / (1024 * 1024)
            total_size_mb += size_mb
            
            if size_mb > max_file_size_mb:
                large_files.append((file_path, size_mb))
            else:
                small_files.append((file_path, size_mb))
            
            file_scan_pbar.update(1)
    
    file_scan_pbar.close()
    
    total_files = len(small_files) + len(large_files)
    print(f"ğŸ“Š íŒŒì¼ ë¶„ì„ ì™„ë£Œ:")
    print(f"   - ì‘ì€ íŒŒì¼: {len(small_files)}ê°œ")
    print(f"   - í° íŒŒì¼: {len(large_files)}ê°œ")
    print(f"   - ì´ í¬ê¸°: {total_size_mb:.1f}MB")
    
    # ì§„í–‰ìƒí™© ì¶”ì ê¸° ì´ˆê¸°í™”
    progress_tracker = UploadProgressTracker(total_files, total_size_mb)
    
    try:
        # 1. ì‘ì€ íŒŒì¼ë“¤ ë¨¼ì € ì—…ë¡œë“œ
        print("\nğŸ“¤ ì‘ì€ íŒŒì¼ë“¤ ì—…ë¡œë“œ ì¤‘...")
        for file_path, size_mb in small_files:
            try:
                relative_path = file_path.relative_to(model_path)
                artifact_path = f"model/{relative_path.parent}" if relative_path.parent != Path('.') else "model"
                
                progress_tracker.update_current_file(str(relative_path), size_mb)
                client.log_artifact(run_id, str(file_path), artifact_path)
                progress_tracker.complete_file(size_mb)
                
                time.sleep(0.5)  # ì„œë²„ ë¶€í•˜ ë°©ì§€
                
            except Exception as e:
                print(f"\nâŒ íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {relative_path} - {e}")
                progress_tracker.complete_file(0)  # ì‹¤íŒ¨í•´ë„ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        
        # 2. í° íŒŒì¼ë“¤ ê°œë³„ ì—…ë¡œë“œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        print("\nğŸ“¤ í° íŒŒì¼ë“¤ ì—…ë¡œë“œ ì¤‘...")
        for file_path, size_mb in large_files:
            relative_path = file_path.relative_to(model_path)
            progress_tracker.update_current_file(str(relative_path), size_mb)
            
            # ì¬ì‹œë„ ë¡œì§
            max_retries = 3
            upload_success = False
            
            for attempt in range(max_retries):
                try:
                    artifact_path = f"model/{relative_path.parent}" if relative_path.parent != Path('.') else "model"
                    client.log_artifact(run_id, str(file_path), artifact_path)
                    upload_success = True
                    break
                    
                except Exception as e:
                    if attempt < max_retries - 1:
                        wait_time = (attempt + 1) * 10
                        print(f"\nâš ï¸ ì¬ì‹œë„ {attempt + 1}/{max_retries}: {relative_path} - {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                        time.sleep(wait_time)
                    else:
                        print(f"\nâŒ ìµœì¢… ì‹¤íŒ¨: {relative_path} - {e}")
            
            if upload_success:
                progress_tracker.complete_file(size_mb)
            else:
                progress_tracker.complete_file(0)  # ì‹¤íŒ¨í•´ë„ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            
            time.sleep(2)  # í° íŒŒì¼ ê°„ ëŒ€ê¸° ì‹œê°„
    
    finally:
        progress_tracker.close()

def create_model_registry_entry(run_id, model_name, model_path):
    """
    ëª¨ë¸ì„ Model Registryì— ë“±ë¡
    """
    try:
        client = MlflowClient()
        
        # ëª¨ë¸ URI ìƒì„±
        model_uri = f"runs:/{run_id}/model"
        
        # ëª¨ë¸ ë“±ë¡
        print(f"ğŸ“ Model Registryì— '{model_name}' ë“±ë¡ ì¤‘...")
        model_version = mlflow.register_model(
            model_uri=model_uri,
            name=model_name
        )
        
        print(f"âœ… ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤: {model_name} v{model_version.version}")
        return model_version
        
    except Exception as e:
        print(f"âŒ Model Registry ë“±ë¡ ì‹¤íŒ¨: {e}")
        return None

def upload_model_with_retry(model_path, model_name="gemma-2b-code-finetuned", max_retries=3):
    """
    ëª¨ë¸ ì—…ë¡œë“œ ë©”ì¸ í•¨ìˆ˜ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    """
    if not check_mlflow_server():
        print("âŒ MLflow ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    model_path = Path(model_path)
    if not model_path.exists():
        print(f"âŒ ëª¨ë¸ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
        return False
    
    print(f"ğŸš€ ëª¨ë¸ ì—…ë¡œë“œ ì‹œì‘: {model_path}")
    
    # ìƒˆë¡œìš´ MLflow run ì‹œì‘
    with mlflow.start_run(run_name=f"model-upload-{datetime.now().strftime('%Y%m%d_%H%M%S')}"):
        run_id = mlflow.active_run().info.run_id
        print(f"ğŸ“‹ MLflow Run ID: {run_id}")
        
        # ëª¨ë¸ ì •ë³´ ë¡œê¹…
        model_info = {
            "model_name": model_name,
            "model_path": str(model_path),
            "upload_time": datetime.now().isoformat(),
            "model_type": "merged_full_model" if "merged" in str(model_path) else "lora_adapter",
            "ollama_compatible": "merged" in str(model_path)
        }
        
        mlflow.log_params(model_info)
        
        # ëª¨ë¸ íŒŒì¼ í¬ê¸° í™•ì¸
        total_size = sum(f.stat().st_size for f in model_path.rglob("*") if f.is_file())
        total_size_mb = total_size / (1024 * 1024)
        print(f"ğŸ“Š ì´ ëª¨ë¸ í¬ê¸°: {total_size_mb:.1f}MB")
        
        mlflow.log_metric("model_size_mb", total_size_mb)
        
        print(f"\nğŸš€ ì—…ë¡œë“œ ì‹œì‘: {model_name}")
        print(f"ğŸ“ Run ID: {run_id}")
        print("=" * 60)
        
        # ì²­í¬ ì—…ë¡œë“œ ì‹œë„
        try:
            upload_large_files_chunked(model_path, run_id)
            
            # ëª¨ë¸ ì •ë³´ íŒŒì¼ ìƒì„±
            info_file = "upload_info.json"
            with open(info_file, "w") as f:
                json.dump(model_info, f, indent=2)
            
            mlflow.log_artifact(info_file)
            os.remove(info_file)
            
            # Model Registryì— ë“±ë¡
            model_version = create_model_registry_entry(run_id, model_name, model_path)
            
            if model_version:
                print(f"\nğŸ‰ ëª¨ë¸ ì—…ë¡œë“œ ì™„ë£Œ!")
                print(f"   - Run ID: {run_id}")
                print(f"   - Model Name: {model_name}")
                print(f"   - Version: {model_version.version}")
                print(f"   - MLflow UI: {MLFLOW_URI}#/experiments")
                return True
            else:
                print("\nâš ï¸ íŒŒì¼ ì—…ë¡œë“œëŠ” ì„±ê³µí–ˆì§€ë§Œ Model Registry ë“±ë¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return False
                
        except Exception as e:
            print(f"âŒ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False

def find_latest_model():
    """ìµœì‹  ëª¨ë¸ ê²½ë¡œë¥¼ ì°¾ëŠ” í•¨ìˆ˜"""
    base_path = "/datasets/github-code"
    model_dirs = []
    
    # ëª¨ë“  ëª¨ë¸ ë””ë ‰í† ë¦¬ ì°¾ê¸°
    for item in os.listdir(base_path):
        item_path = os.path.join(base_path, item)
        if os.path.isdir(item_path) and ("finetuned" in item or "gemma" in item):
            # config.jsonì´ ìˆëŠ”ì§€ í™•ì¸ (ìœ íš¨í•œ ëª¨ë¸ì¸ì§€ í™•ì¸)
            if os.path.exists(os.path.join(item_path, "config.json")):
                model_dirs.append((item, os.path.getmtime(item_path)))
    
    if not model_dirs:
        return None, None
    
    # ìµœì‹  ëª¨ë¸ ì°¾ê¸°
    latest_model = max(model_dirs, key=lambda x: x[1])[0]
    
    lora_path = os.path.join(base_path, latest_model)
    merged_path = f"{lora_path}_merged"
    
    return lora_path if os.path.exists(lora_path) else None, merged_path if os.path.exists(merged_path) else None

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="MLflow ëª¨ë¸ ì—…ë¡œë“œ ì¬ì‹œë„ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument("--model-path", type=str, help="ì—…ë¡œë“œí•  ëª¨ë¸ ê²½ë¡œ")
    parser.add_argument("--model-name", type=str, help="MLflowì— ë“±ë¡í•  ëª¨ë¸ëª…")
    parser.add_argument("--auto-detect", action="store_true", help="ìë™ìœ¼ë¡œ ìµœì‹  ëª¨ë¸ ê°ì§€")
    
    args = parser.parse_args()
    
    print("=== MLflow ëª¨ë¸ ì—…ë¡œë“œ ì¬ì‹œë„ ìŠ¤í¬ë¦½íŠ¸ ===")
    
    if args.model_path and args.model_name:
        # ì‚¬ìš©ìê°€ ì§ì ‘ ì§€ì •í•œ ê²½ìš°
        if os.path.exists(args.model_path):
            print(f"\nğŸ¯ ì§€ì •ëœ ëª¨ë¸ ì—…ë¡œë“œ ì‹œë„: {args.model_path}")
            success = upload_model_with_retry(args.model_path, args.model_name)
            if success:
                print("âœ… ëª¨ë¸ ì—…ë¡œë“œ ì™„ë£Œ!")
            else:
                print("âŒ ëª¨ë¸ ì—…ë¡œë“œ ì‹¤íŒ¨")
        else:
            print(f"âŒ ëª¨ë¸ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {args.model_path}")
    
    elif args.auto_detect:
        # ìë™ ê°ì§€
        lora_path, merged_path = find_latest_model()
        
        if not lora_path and not merged_path:
            print("âŒ ì—…ë¡œë“œí•  ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë³‘í•©ëœ ëª¨ë¸ ìš°ì„  ì—…ë¡œë“œ
        if merged_path:
            model_name = os.path.basename(merged_path).replace("_merged", "")
            print(f"\nğŸ¯ ë³‘í•©ëœ ëª¨ë¸ (Ollama í˜¸í™˜) ì—…ë¡œë“œ ì‹œë„: {merged_path}")
            success = upload_model_with_retry(merged_path, f"{model_name}-merged")
            if success:
                print("âœ… ë³‘í•©ëœ ëª¨ë¸ ì—…ë¡œë“œ ì™„ë£Œ!")
            else:
                print("âŒ ë³‘í•©ëœ ëª¨ë¸ ì—…ë¡œë“œ ì‹¤íŒ¨")
        
        # LoRA ëª¨ë¸ ì—…ë¡œë“œ
        if lora_path:
            model_name = os.path.basename(lora_path)
            print(f"\nğŸ¯ LoRA ì–´ëŒ‘í„° ëª¨ë¸ ì—…ë¡œë“œ ì‹œë„: {lora_path}")
            success = upload_model_with_retry(lora_path, f"{model_name}-lora")
            if success:
                print("âœ… LoRA ëª¨ë¸ ì—…ë¡œë“œ ì™„ë£Œ!")
            else:
                print("âŒ LoRA ëª¨ë¸ ì—…ë¡œë“œ ì‹¤íŒ¨")
    
    else:
        # ê¸°ë³¸ ë™ì‘ (í•˜ë“œì½”ë”©ëœ ê²½ë¡œë“¤)
        print("\nğŸ’¡ ì‚¬ìš©ë²•:")
        print("  python retry_mlflow_upload.py --auto-detect")
        print("  python retry_mlflow_upload.py --model-path <PATH> --model-name <NAME>")
        
        # ê¸°ì¡´ í•˜ë“œì½”ë”©ëœ ê²½ë¡œë“¤ë„ ì‹œë„
        default_paths = [
            ("/datasets/github-code/gemma-2b-code-finetuned_merged", "gemma-2b-code-finetuned-merged"),
            ("/datasets/github-code/gemma-2b-code-finetuned", "gemma-2b-code-finetuned-lora")
        ]
        
        for model_path, model_name in default_paths:
            if os.path.exists(model_path):
                print(f"\nğŸ¯ ê¸°ë³¸ ëª¨ë¸ ì—…ë¡œë“œ ì‹œë„: {model_path}")
                success = upload_model_with_retry(model_path, model_name)
                if success:
                    print(f"âœ… {model_name} ì—…ë¡œë“œ ì™„ë£Œ!")
                else:
                    print(f"âŒ {model_name} ì—…ë¡œë“œ ì‹¤íŒ¨")
    
    print("\n=== ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ì™„ë£Œ ===")

if __name__ == "__main__":
    main() 