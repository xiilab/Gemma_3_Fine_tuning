#!/usr/bin/env python3
"""
MLflowì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ í•™ìŠµì„ ê³„ì†í•˜ëŠ” ì˜ˆì‹œ

ì‚¬ìš© ë°©ë²•:
1. íŠ¹ì • ëª¨ë¸ ì´ë¦„ìœ¼ë¡œ ê³„ì† í•™ìŠµ: python continue_training.py --model-name gemma-2b-code-finetuned
2. íŠ¹ì • run_idë¡œ ê³„ì† í•™ìŠµ: python continue_training.py --run-id abc123def456
3. ìƒˆë¡œìš´ ëª¨ë¸ë¡œ ì‹œì‘: python continue_training.py
"""

import argparse
import json
import mlflow
from mlflow import MlflowClient
from datetime import datetime

def list_available_models():
    """MLflowì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ì¶œë ¥"""
    try:
        client = MlflowClient()
        registered_models = client.search_registered_models()
        if registered_models:
            print("\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡:")
            for model in registered_models:
                print(f"  - {model.name}")
                # ìµœì‹  ë²„ì „ ì •ë³´ë„ ì¶œë ¥
                try:
                    latest_version = client.get_latest_versions(model.name, stages=["None"])[0]
                    print(f"    ìµœì‹  ë²„ì „: {latest_version.version}")
                    print(f"    Run ID: {latest_version.run_id}")
                except:
                    pass
        else:
            print("\nâŒ ë“±ë¡ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")

def list_recent_runs():
    """ìµœê·¼ í•™ìŠµ ì‹¤í–‰ ëª©ë¡ì„ ì¶œë ¥"""
    try:
        client = MlflowClient()
        experiment = client.get_experiment_by_name("Gemma-2b-Code-Finetuning")
        if experiment:
            runs = client.search_runs(
                experiment_ids=[experiment.experiment_id],
                max_results=10,
                order_by=["start_time DESC"]
            )
            if runs:
                print("\nğŸ“‹ ìµœê·¼ í•™ìŠµ ì‹¤í–‰ ëª©ë¡:")
                for run in runs:
                    print(f"  - Run ID: {run.info.run_id}")
                    print(f"    ì‹œì‘ ì‹œê°„: {run.info.start_time}")
                    print(f"    ìƒíƒœ: {run.info.status}")
                    if run.data.metrics:
                        final_loss = run.data.metrics.get("final_loss", "N/A")
                        print(f"    ìµœì¢… Loss: {final_loss}")
                    print()
            else:
                print("\nâŒ í•™ìŠµ ì‹¤í–‰ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print("\nâŒ ì‹¤í—˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")

def main():
    parser = argparse.ArgumentParser(description="MLflowì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ í•™ìŠµ ê³„ì†")
    parser.add_argument("--model-name", type=str, help="MLflow Model Registryì—ì„œ ë¡œë“œí•  ëª¨ë¸ ì´ë¦„")
    parser.add_argument("--run-id", type=str, help="íŠ¹ì • run_idì—ì„œ ëª¨ë¸ì„ ë¡œë“œ")
    parser.add_argument("--new-model-name", type=str, help="ìƒˆë¡œìš´ ëª¨ë¸ëª… (ì €ì¥ë  ë•Œ ì‚¬ìš©)")
    parser.add_argument("--epochs", type=int, default=1, help="ì¶”ê°€ í•™ìŠµí•  ì—í¬í¬ ìˆ˜")
    parser.add_argument("--learning-rate", type=float, default=2e-4, help="í•™ìŠµë¥ ")
    parser.add_argument("--batch-size", type=int, default=2, help="ë°°ì¹˜ í¬ê¸°")
    parser.add_argument("--dataset-start", type=int, default=0, help="ë°ì´í„°ì…‹ ì‹œì‘ ì¸ë±ìŠ¤")
    parser.add_argument("--dataset-end", type=int, default=10000, help="ë°ì´í„°ì…‹ ë ì¸ë±ìŠ¤ (exclusive)")
    parser.add_argument("--list-models", action="store_true", help="ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¶œë ¥")
    parser.add_argument("--list-runs", action="store_true", help="ìµœê·¼ í•™ìŠµ ì‹¤í–‰ ëª©ë¡ ì¶œë ¥")
    parser.add_argument("--auto-launch", action="store_true", help="íŒŒë¼ë¯¸í„° ì„¤ì • í›„ ìë™ìœ¼ë¡œ main.py ì‹¤í–‰")
    parser.add_argument("--upload-retry", action="store_true", help="í•™ìŠµ í›„ MLflow ì—…ë¡œë“œ ì¬ì‹œë„")
    parser.add_argument("--mlflow-uri", type=str, default="http://10.61.3.161:30366/", help="MLflow ì„œë²„ ì£¼ì†Œ")
    
    args = parser.parse_args()
    
    # MLflow ì„¤ì •
    MLFLOW_URI = args.mlflow_uri
    mlflow.set_tracking_uri(MLFLOW_URI)
    
    if args.list_models:
        list_available_models()
        return
    
    if args.list_runs:
        list_recent_runs()
        return
    
    print("=== MLflow ëª¨ë¸ ì—°ì† í•™ìŠµ ì„¤ì • ===")
    print(f"ëª¨ë¸ ì´ë¦„: {args.model_name}")
    print(f"Run ID: {args.run_id}")
    print(f"ì¶”ê°€ ì—í¬í¬: {args.epochs}")
    print(f"í•™ìŠµë¥ : {args.learning_rate}")
    print(f"ë°°ì¹˜ í¬ê¸°: {args.batch_size}")
    print(f"ë°ì´í„°ì…‹ ë²”ìœ„: {args.dataset_start} ~ {args.dataset_end} (ì´ {args.dataset_end - args.dataset_start}ê°œ)")
    print("=" * 40)
    
    # main.pyì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìˆ˜ì •í•˜ì—¬ í•™ìŠµ ê³„ì†
    from main import hyperparams
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
    hyperparams["continue_from_model"] = args.model_name
    hyperparams["continue_from_run_id"] = args.run_id
    hyperparams["new_model_name"] = args.new_model_name
    hyperparams["num_epochs"] = args.epochs
    hyperparams["learning_rate"] = args.learning_rate
    hyperparams["batch_size"] = args.batch_size
    hyperparams["dataset_start"] = args.dataset_start
    hyperparams["dataset_end"] = args.dataset_end
    
    print("âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    if args.upload_retry:
        print("ğŸ”„ MLflow ì—…ë¡œë“œ ì¬ì‹œë„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")
        import subprocess
        import sys
        try:
            result = subprocess.run([
                sys.executable, "retry_mlflow_upload.py", "--auto-detect"
            ], check=True, capture_output=False)
            print("âœ… MLflow ì—…ë¡œë“œ ì¬ì‹œë„ ì™„ë£Œ!")
        except subprocess.CalledProcessError as e:
            print(f"âŒ MLflow ì—…ë¡œë“œ ì¬ì‹œë„ ì‹¤íŒ¨: {e}")
    else:
        print("ğŸš€ main.pyë¥¼ ì‹¤í–‰í•˜ì—¬ í•™ìŠµì„ ì‹œì‘í•˜ì„¸ìš”:")
        print("   accelerate launch main.py")
        print("   ë˜ëŠ”")
        print("   python main.py")
        print("\nğŸ’¡ MLflow ì—…ë¡œë“œ ì¬ì‹œë„:")
        print("   python retry_mlflow_upload.py --auto-detect")

if __name__ == "__main__":
    main() 