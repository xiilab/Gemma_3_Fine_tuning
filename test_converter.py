#!/usr/bin/env python3
"""
MLflow to Ollama ë³€í™˜ê¸° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì£¼ì¸ë‹˜ì˜ ë³€í™˜ê¸°ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê³  ê²€ì¦í•©ë‹ˆë‹¤.
"""

import sys
import os
from mlflow_to_ollama_converter import MLflowToOllamaConverter

def test_mlflow_connection():
    """MLflow ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª MLflow ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        converter = MLflowToOllamaConverter()
        print("âœ… MLflow ì—°ê²° ì„±ê³µ!")
        return True
    except Exception as e:
        print(f"âŒ MLflow ì—°ê²° ì‹¤íŒ¨: {e}")
        return False

def test_list_models():
    """ëª¨ë¸ ëª©ë¡ ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª ëª¨ë¸ ëª©ë¡ ì¡°íšŒ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        converter = MLflowToOllamaConverter()
        models = converter.list_available_models()
        
        if models:
            print(f"âœ… ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì„±ê³µ! ({len(models)}ê°œ ëª¨ë¸ ë°œê²¬)")
            return True, models
        else:
            print("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return True, []
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return False, []

def test_ollama_installation():
    """Ollama ì„¤ì¹˜ í™•ì¸"""
    print("\nğŸ§ª Ollama ì„¤ì¹˜ í™•ì¸ ì¤‘...")
    
    try:
        import subprocess
        result = subprocess.run(["ollama", "--version"], 
                              capture_output=True, text=True, check=True)
        print(f"âœ… Ollama ì„¤ì¹˜ë¨: {result.stdout.strip()}")
        return True
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("âŒ Ollamaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ì„¤ì¹˜ ë°©ë²•: curl -fsSL https://ollama.ai/install.sh | sh")
        return False

def interactive_test():
    """ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸"""
    print("\nğŸ¤– ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    print("=" * 50)
    
    # MLflow ì—°ê²° í…ŒìŠ¤íŠ¸
    if not test_mlflow_connection():
        return False
    
    # ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
    success, models = test_list_models()
    if not success:
        return False
    
    if not models:
        print("ë³€í™˜í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    # Ollama ì„¤ì¹˜ í™•ì¸
    if not test_ollama_installation():
        print("Ollamaë¥¼ ë¨¼ì € ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        return False
    
    # ì‚¬ìš©ì ì…ë ¥
    print(f"\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ({len(models)}ê°œ):")
    for i, model in enumerate(models[:5]):  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
        print(f"{i+1}. {model['run_id'][:8]}... - {model['run_name']}")
    
    try:
        choice = input("\në³€í™˜í•  ëª¨ë¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-5, 0=ì·¨ì†Œ): ").strip()
        
        if choice == '0':
            print("í…ŒìŠ¤íŠ¸ë¥¼ ì·¨ì†Œí•©ë‹ˆë‹¤.")
            return True
        
        choice_idx = int(choice) - 1
        if 0 <= choice_idx < len(models) and choice_idx < 5:
            selected_model = models[choice_idx]
            run_id = selected_model['run_id']
            
            model_name = input(f"ëª¨ë¸ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ê¸°ë³¸ê°’: gemma-code-{run_id[:8]}): ").strip()
            if not model_name:
                model_name = f"gemma-code-{run_id[:8]}"
            
            print(f"\nğŸš€ ëª¨ë¸ ë³€í™˜ ì‹œì‘...")
            print(f"Run ID: {run_id}")
            print(f"ëª¨ë¸ ì´ë¦„: {model_name}")
            
            # ì‹¤ì œ ë³€í™˜ ì‹¤í–‰
            converter = MLflowToOllamaConverter()
            success = converter.convert_model(run_id, model_name)
            
            if success:
                print(f"\nğŸ‰ ë³€í™˜ ì™„ë£Œ!")
                print(f"ì‚¬ìš©ë²•: ollama run {model_name}")
                return True
            else:
                print(f"\nâŒ ë³€í™˜ ì‹¤íŒ¨!")
                return False
        else:
            print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
            return False
            
    except ValueError:
        print("ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return False
    except KeyboardInterrupt:
        print("\n\nì‚¬ìš©ìê°€ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
        return True

def main():
    print("ğŸ§ª MLflow to Ollama ë³€í™˜ê¸° í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    if len(sys.argv) > 1 and sys.argv[1] == "--interactive":
        interactive_test()
    else:
        # ê¸°ë³¸ í…ŒìŠ¤íŠ¸
        print("ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        if not test_mlflow_connection():
            sys.exit(1)
        
        # ëª¨ë¸ ëª©ë¡ í…ŒìŠ¤íŠ¸
        success, models = test_list_models()
        if not success:
            sys.exit(1)
        
        # Ollama ì„¤ì¹˜ í™•ì¸
        test_ollama_installation()
        
        print(f"\nâœ… ëª¨ë“  ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ë¥¼ ì›í•˜ë©´: python {__file__} --interactive")

if __name__ == "__main__":
    main() 